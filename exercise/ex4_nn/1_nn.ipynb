{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "Implement the backpropagation algorithm for neural networks and apply it to the task of hand-written digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(path):\n",
    "    data = loadmat(path)\n",
    "    return data['Theta1'], data['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    }
   ],
   "source": [
    "theta_1, theta_2 = load_parameters(\"ex4weights.mat\")\n",
    "print(theta_1.shape)\n",
    "print(theta_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(theta_seq):\n",
    "    '''\n",
    "    Serialize theta_1(25, 401) and theta_2(10, 26) to serialized theta(10285,)\n",
    "    '''\n",
    "    res = None\n",
    "    \n",
    "    for i in range(1, len(theta_seq)):\n",
    "        res = np.concatenate((theta_seq[0].ravel(), theta_seq[i].ravel()))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10285,)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = serialize([theta_1, theta_2])\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(theta):\n",
    "    '''\n",
    "    Deserialize theta(10285,) to theta_1(25, 401) and theta_2(10, 26)\n",
    "    '''\n",
    "    return [theta[:25 * 401].reshape((25, 401)), theta[25 * 401:].reshape((10, 26))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    }
   ],
   "source": [
    "t1, t2 = deserialize(theta)\n",
    "print(t1.shape)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = loadmat(path)\n",
    "    return data['X'], data['y'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    '''\n",
    "    Transform y from (5000,) to (10, 5000)\n",
    "    if y_i = 1 then after transformation y_i = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    '''\n",
    "    y_matrix = []\n",
    "    for i in range(1, 11):\n",
    "        y_matrix.append((y == i).astype(int))\n",
    "    return np.array(y_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(5000, 400)\n",
      "(10, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_data(\"ex4data1.mat\")\n",
    "raw_y = y.copy()\n",
    "print(y.shape)\n",
    "y = transform_y(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feedfoward propagation\n",
    "\n",
    "Implement the foward-propagation algorithm to use trained parameters to predict.\n",
    "\n",
    "<img src=\"../ex3_multi_classification/nn_model.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (np.exp(-z) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_propagation(theta, X):\n",
    "    '''\n",
    "    Feedfoward propagation algorithm\n",
    "    '''\n",
    "    theta = deserialize(theta)\n",
    "    a = [X]\n",
    "    z = []\n",
    "    \n",
    "    for t in theta:\n",
    "        a[-1] = np.insert(a[-1], 0, values=np.ones(a[-1].shape[0]), axis=1)\n",
    "        z.append(a[-1] @ t.T)\n",
    "        a.append(sigmoid(z[-1]))\n",
    "        \n",
    "    return a, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.127e-04, 1.741e-03, 2.527e-03, ..., 4.015e-04, 6.481e-03,\n",
       "        9.957e-01],\n",
       "       [4.790e-04, 2.415e-03, 3.448e-03, ..., 2.391e-03, 1.970e-03,\n",
       "        9.957e-01],\n",
       "       [8.857e-05, 3.243e-03, 2.554e-02, ..., 6.229e-02, 5.498e-03,\n",
       "        9.280e-01],\n",
       "       ...,\n",
       "       [5.176e-02, 3.817e-03, 2.963e-02, ..., 2.157e-03, 6.498e-01,\n",
       "        2.424e-05],\n",
       "       [8.306e-04, 6.220e-04, 3.145e-04, ..., 1.194e-02, 9.714e-01,\n",
       "        2.062e-04],\n",
       "       [4.815e-05, 4.588e-04, 2.151e-05, ..., 5.734e-03, 6.963e-01,\n",
       "        8.186e-02]])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = foward_propagation(theta, X)\n",
    "\n",
    "print(a[2].shape)\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Regularized cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function of neural network is defined as $$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^K\\left[-y_k^{(i)}\\log\\left(h_\\theta\\left(x^{(i)}\\right)_k\\right)-\\left(1-y^{(i)}_k\\right)\\log\\left(1-h_\\theta\\left(x^{(i)}\\right)_k\\right)\\right]$$where $K = 10$ in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    '''\n",
    "    Compute cost function of neural network\n",
    "    '''\n",
    "    a, _ = foward_propagation(theta, X)\n",
    "    error = -np.multiply(y.T, np.log(a[-1])) - np.multiply(1 - y.T, np.log(1 - a[-1]))\n",
    "    return error.sum() / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876291651613189"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularized cost function of neural network is given by $$J(\\theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^K\\left[-y_k^{(i)}\\log\\left(h_\\theta\\left(x^{(i)}\\right)_k\\right)-\\left(1-y^{(i)}_k\\right)\\log\\left(1-h_\\theta\\left(x^{(i)}\\right)_k\\right)\\right] + \\frac{\\lambda}{2m}\\left[\\sum_{j=1}^{25}\\sum_{k=1}^{400}\\left(\\theta_{jk}^{(1)}\\right)^2+\\sum_{j=1}^{10}\\sum_{k=1}^{25}\\left(\\theta_{jk}^{(2)}\\right)^2\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_cost(theta, X, y, reg):\n",
    "    '''\n",
    "    Compute regularized cost function of neural network\n",
    "    '''\n",
    "    t1, t2 = deserialize(theta)\n",
    "    reg_t1 = np.power(t1[:, 1:], 2).sum()\n",
    "    reg_t2 = np.power(t2[:, 1:], 2).sum()\n",
    "    return cost(theta, X, y) + (reg / (2 * len(X))) * (reg_t1 + reg_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38376985909092365"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularized_cost(theta, X, y, reg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Backpropagation\n",
    "\n",
    "<img src=\"backpropagation.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    '''\n",
    "    Compute sigmoid gradient.\n",
    "    g'(z) = g(z)(1 - g(z))\n",
    "    '''\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_gradient(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation algorithm without regularization$$\\delta^{(l)} = \\begin{cases}h_\\theta(x) - y & l = L \\\\ \\left(\\theta^{(l)}\\right)^T\\delta^{(l+1)}\\bigodot g'\\left(z^{(l)}\\right) & l = 2, 3, \\dots, L - 1\\end{cases} \\\\ \\frac{\\partial}{\\partial\\theta^{(l)}}J(\\theta) = D^{(l)}=\\frac{1}{m}\\Delta^{(l)} = \\frac{1}{m}\\sum_{i=1}^m\\delta^{(l+1)}\\left(a^{(l)}\\right)^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    '''\n",
    "    Compute gradient without regularization\n",
    "    '''\n",
    "    a, z = foward_propagation(theta, X)\n",
    "    h = a[-1]\n",
    "    \n",
    "    theta = deserialize(theta)\n",
    "    delta = [np.zeros(theta[i].shape) for i in range(len(theta))]    \n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        di = h[i, :] - y.T[i, :]\n",
    "        ai = a[-2][i, :]\n",
    "        delta[-1] += di.reshape(len(di), 1) @ ai.reshape(1, len(ai))\n",
    "        \n",
    "        for j in range(len(z) - 1, 0, -1):\n",
    "            zi = np.insert(z[j - 1][i, :], 0, values=np.ones(1))\n",
    "            di = np.multiply(theta[j].T @ di, sigmoid_gradient(zi))[1:]\n",
    "            ai = a[j - 1][i, :]\n",
    "            \n",
    "            delta[j - 1] += di.reshape(len(di), 1) @ ai.reshape(1, len(ai))\n",
    "        \n",
    "    for delta_i in delta:\n",
    "        delta_i /= len(X)\n",
    "    \n",
    "    return serialize(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = deserialize(gradient(theta, X, y))\n",
    "print(d1.shape, d2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation algorithm with regulariz$$\\frac{\\partial}{\\partial \\theta^{(l)}}J(\\theta)=D^{(l)}=\\begin{cases}\\frac{1}{m}\\Delta^{(l)} & j = 0 \\\\ \\frac{1}{m}\\Delta^{(l)}+\\frac{\\lambda}{m}\\theta^{(l)} & j \\geq 1\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_gradient(theta, X, y, reg):\n",
    "    delta = deserialize(gradient(theta, X, y))\n",
    "    theta = deserialize(theta)\n",
    "    \n",
    "    for i in range(len(delta)):\n",
    "        t = theta[i]\n",
    "        t[:, 0] = 0\n",
    "        term = (reg / len(X)) * t\n",
    "        delta[i] += term\n",
    "    \n",
    "    return serialize(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = deserialize(regularized_gradient(theta, X, y, 1))\n",
    "print(d1.shape, d2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_init(size, epsilon):\n",
    "    '''\n",
    "    Select values for theta uniformly in [-ùúñ, ùúñ]\n",
    "    '''\n",
    "    return np.random.uniform(-epsilon, epsilon, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(X, y, size):\n",
    "    theta_0 = rand_init(size, 0.12)\n",
    "    \n",
    "    res = opt.minimize(fun=regularized_cost, \n",
    "                       x0=theta_0, \n",
    "                       args=(X, y, 1), \n",
    "                       method='TNC', \n",
    "                       jac=regularized_gradient, \n",
    "                       options={'maxiter': 400})\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.31974402406911195\n",
       "     jac: array([-6.380e-05,  1.152e-08, -5.934e-09, ...,  4.755e-05,  4.627e-05,\n",
       "        8.364e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 400\n",
       "     nit: 26\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 0.000e+00,  5.760e-05, -2.967e-05, ..., -8.039e-02, -1.512e+00,\n",
       "       -3.436e-01])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = nn(X, y, len(theta))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_theta = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(theta, X, y):\n",
    "    a, _ = foward_propagation(theta, X)\n",
    "    h = a[-1]\n",
    "    y_pred = np.argmax(h, axis=1) + 1\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      1.00      0.98       500\n",
      "           2       0.98      0.96      0.97       500\n",
      "           3       0.88      0.98      0.93       500\n",
      "           4       0.98      0.97      0.97       500\n",
      "           5       1.00      0.73      0.84       500\n",
      "           6       0.97      0.99      0.98       500\n",
      "           7       0.89      1.00      0.94       500\n",
      "           8       0.96      0.98      0.97       500\n",
      "           9       0.98      0.90      0.94       500\n",
      "          10       0.92      1.00      0.96       500\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5000\n",
      "   macro avg       0.95      0.95      0.95      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_accuracy(fin_theta, X, raw_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
